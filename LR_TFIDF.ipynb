{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing baseline model with `CountVectorizer()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "X = df['text']\n",
    "Y = df['suicide']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "### WordVectorization with `CountVectorizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X_set = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (185659, 146321)\n",
      "Shape of Y: (185659,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X_set.shape)\n",
    "print(\"Shape of Y:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the baseline model\n",
    "\n",
    "For testing purposes, we will use the Logistic Regression classifier `LogisticRegression()` with its default settings as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Baseline Model\n",
    "\n",
    "### 5-fold Stratified Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1\n",
      "\taccuracy_score: 0.9364\n",
      "\trecall_score: 0.9251\n",
      "\tprecision_score: 0.9465\n",
      "\tf1_score: 0.9357\n",
      "Time:  2\n",
      "\taccuracy_score: 0.9340\n",
      "\trecall_score: 0.9221\n",
      "\tprecision_score: 0.9445\n",
      "\tf1_score: 0.9332\n",
      "Time:  3\n",
      "\taccuracy_score: 0.9358\n",
      "\trecall_score: 0.9234\n",
      "\tprecision_score: 0.9470\n",
      "\tf1_score: 0.9350\n",
      "Time:  4\n",
      "\taccuracy_score: 0.9346\n",
      "\trecall_score: 0.9246\n",
      "\tprecision_score: 0.9435\n",
      "\tf1_score: 0.9339\n",
      "Time:  5\n",
      "\taccuracy_score: 0.9331\n",
      "\trecall_score: 0.9201\n",
      "\tprecision_score: 0.9448\n",
      "\tf1_score: 0.9323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=60)\n",
    "accuracy_score_list, recall_score_list, precision_score_list, f1_score_list = [], [], [], []\n",
    "\n",
    "for time, (train_index, test_index) in enumerate(skfolds.split(X_set, Y)):\n",
    "    X_train, X_test = X_set[train_index], X_set[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    AccuracyScore = accuracy_score(Y_test, y_pred)\n",
    "    RecallScore = recall_score(Y_test, y_pred)\n",
    "    PrecisionScore = precision_score(Y_test, y_pred)\n",
    "    F1Score = f1_score(Y_test, y_pred)\n",
    "\n",
    "    # Add to lists\n",
    "    accuracy_score_list.append(AccuracyScore)\n",
    "    recall_score_list.append(RecallScore)\n",
    "    precision_score_list.append(PrecisionScore)\n",
    "    f1_score_list.append(F1Score)\n",
    "\n",
    "    # Print the matrix\n",
    "    print('Time: ', time + 1)\n",
    "    print('\\taccuracy_score: {:.4f}'.format(AccuracyScore))\n",
    "    print('\\trecall_score: {:.4f}'.format(RecallScore))\n",
    "    print('\\tprecision_score: {:.4f}'.format(PrecisionScore))\n",
    "    print('\\tf1_score: {:.4f}'.format(F1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.48%\n",
      "Recall: 92.31%\n",
      "Precision: 94.52%\n",
      "F1_score: 93.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Print the average value of each matrix\n",
    "print(\"Accuracy: {:.2%}\".format(np.average(accuracy_score_list)))\n",
    "print(\"Recall: {:.2%}\".format(np.average(recall_score_list)))\n",
    "print(\"Precision: {:.2%}\".format(np.average(precision_score_list)))\n",
    "print(\"F1_score: {:.2%}\".format(np.average(f1_score_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "clf.fit(X_set, Y)\n",
    "\n",
    "print(clf.n_iter_)\n",
    "\n",
    "with open('./model/LR_tfidf.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using code below to load the fitted model:\n",
    "\n",
    "``` python\n",
    "with open('./model/LR_tfidf.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39526121]\n",
      "[-1.40760916]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "print(clf.coef_[:, vocabulary['happy']])\n",
    "print(clf.coef_[:, vocabulary['sad']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights for class 0:\n",
      "\n",
      "alive with weight 6.09891424630061\n",
      "end with weight 6.826371198324343\n",
      "mei with weight 6.966087497314663\n",
      "life with weight 7.137644291173986\n",
      "killing with weight 7.177212623579987\n",
      "die with weight 7.484886073292844\n",
      "pills with weight 8.251502189073777\n",
      "kill with weight 10.459847896200468\n",
      "suicidal with weight 13.777891466483391\n",
      "suicide with weight 16.435349080808024\n"
     ]
    }
   ],
   "source": [
    "n_feats_to_show = 10\n",
    "\n",
    "# Flip the index so that values are keys and keys are values:\n",
    "keys = vectorizer.vocabulary_.values()\n",
    "values = vectorizer.vocabulary_.keys()\n",
    "vocab_inverted = dict(zip(keys, values))\n",
    "\n",
    "for c, weights_c in enumerate(clf.coef_):\n",
    "    print(f'\\nWeights for class {c}:\\n')\n",
    "    strongest_idxs = np.argsort(weights_c)[-n_feats_to_show:]\n",
    "\n",
    "    for idx in strongest_idxs:\n",
    "        print(f'{vocab_inverted[idx]} with weight {weights_c[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
